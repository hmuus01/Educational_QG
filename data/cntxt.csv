context
this is very preliminary work that it's just,recently on the the thing about the in katie thinking,system this is sort of agenda so why are we interested in this problem what exactly is the problem and why it,is a problem how we cannot solve it how we tried,solving solving it and what we tried what we trying the future in order to,solve better so i'm we interested in this problem as marker said recently are one year ago we started to work on,european project called alert and the overall goal of the to improve,the by the solution process in open source environments and at the end of the project we hope to,have a set of tools that will help to and developers so to improved the overview of the project improve the communication between the developers and the users so just people who can solve a bug in,one of the task is also to be able to detect a bug duplicates in,back tracking systems so what what about the pickets i guess most of your software developers,so i guess you know what tracking system,of systems are that nonetheless suggests and we can give a quick introduction so back tracking systems are tools that we can use users can users of a particular product can use in order to be to report some issues,that they did detected with the softer back to the developers and there are several platforms that we,can use as buffering systems such as bugzilla,monkeys and launchpad i'll just show a quick look at how o example looks like so let's said to one reports on new body so we first have to specify some title the box and then provides some detailed description of,the bug so in this description we should,give enough information for the developers to be,able to reproduce the bug and also to,solve it after we pose the back very often people can post comments we can see here a list of comments in,these comments people can ask for,additional information about the box are they can provide some additional,information how to replicate the bag and,so on along with the description these comments we also have,some meta information we but in this case because it allows us to to specify the,products of the word is but belongs to some component so component is part of,the product and also some additional information,like is about new so on the target the version with this bug,appears and so on so many what's really important is meta,information is the data the box so when the by by was reported first and also the product and component so but systems are very useful but they have a problem and the problem,is that when users reported bug issues that,typically don't check if the same issue,was already reported in the past so what people,typically happens is that create some new bug reports describes the same but,it was already reported in the past and when that happens we say that they,have created a bug duplicates so why are but i think it's a problem i illustrate this problem in the case of,katie it is a large organization which is also used case partner in the the have about one thousand eight hundred developers,who develops more than six million,zlotys lines of code the using a bugzilla as the bug tracking,system and they have repository containing over,a quarter of a million about reports here is a graph that shows the number of bug reports for month and you can see that it's this set up,bugzilla around in nineteen ninety nine and then for some time and opportunity but after,then we have about two thousand five reports,from on except in the last two years or three,years were the this activity became even even larger what's even more important is that we,also have fifty thousand bug reports,that are marked as duplicates so one thing that i didn't show here in,this report is if i go down we can see some words,but was actually marked is a duplicate of some other above end as an i okay obviously cannot find it right now,but there is yeah and no really this is if you see this has been marked as in the,case of of some other bug so people have to manually check the box and decide if a bug is a duplicate or,not and the in the case of katie they found fifty thousand by reporter,mark them as the tickets and we can also see the this distribution here we can see that,this is the ratio of the kids in,comparison to the reports and we can see that in the case of katie we have about on average twenty percent of bug reports that are actually,duplicates what's also interesting is graph is that,we we see here a very similar so here we have an increase of of bug,duplicates reports and here we have an increase of and over here we have an,increase of reports and this is the increase of the,applicants so obviously then people are reporting more box they also,report significantly larger percentage of the pickets then why you have the above what it but the what we the i have no idea i guess is a difficult,incident that these graphs yeah i so can ease of course not an isolated,case the similar problem was also reported in,other communities for example in firefox the here about forty percent of the,people reports that the kids and one to they have even more they get,sixty two percent reported that this is a course a big issue because dealing with but report states time end this open source projects typically have,people with call back three hours who among other things what they do is they decide if a bug is,a duplicate or not any view if if you consider that we need to let's say a few minutes to decide if a,bug is because they are not and then if we multiply this by,thousands of boxing considered the is an enormous human effort that is,spent in deciding if a bug is it's not because now come to the importing of the,data in order to analyse the data we imported,it into tool that we developed which is called,contextify on intensify originally is used to to,analyse manage but it's very easy to,modify to to also analyzed by reports so far is bad report we constructed a,new document and in these documents we put the original description of the,box plus all the following comments then we transform these documents and,store them in the bag-of-words form when we are forced to move the support,and we apply the porterstemmer along with the bag-of-words also store information about the box like time who posted the,box was the product and components and,so on and so what can we do with this data that,after we reported so this is where machine learning group one thing that we of course always think,about this classification so the question is can we treat this as,a classification problem we consider learning examples are simply,the bug reports the attributes are the words in the,documents plus the meta information and then we have to somehow decide what,is the class so the obvious choice is that we say,okay the classes in the bag is a duplicate or not and if you think about it this is a very,bad choice because the above is a duplicate because it has,a very specific relation to one or the,other reports so there is actually no no parents the property that is common for all,about people for all reports that are,duplicates so nothing is we cannot say that there is a specific,word that very often appears in reports,which are duplicates we cannot say that a specific person is,the one who who is the one who often reports,duplicates and so on so there's no,property this allows us to discriminate between these two groups if somebody still not come that around,experiments and of course the accuracy,is very low it's below sixty percent and also,precision and recall is slow the in the it weather about this is get are not but what is the right you say the majority class which is eighty percent so we considered no bugs in the it's so the second thing that we can think of,these that create class value for each bug report so each by,report has a different class value and we tried to have a new bug report we,can try to classify it as one of these,existing into one of these existing class values this is again a very bad choice because,in this case we would have an enormous,number of classes and that is a course no ability to,generalize because we typically have,just one example per class value so no machine learning can create something general from this so if you cannot classify what can we do i one thing that we can do of course is,wearing so let's say that we are given a report,by then we can rank the reports based on the likelihood that this other reports the original box of this but be i so we will somehow i want to see i think list where original bag is very high in this list,of of a similar reports we can compute this ranking on many number of ways and one ways based on the content similarity so we compared the content of the box and we hope that the original box and the kids have very,similar content in this case we don't s tell the user in these blog are,duplicate or not but we can provide,human alan greatly stuff reports and then the user can decide if it is are not compute dissimilarities really users standard fideus weighting scheme end we compute its cause and similarity been on to documents the this is called plus the subject plus the ah called comments basically all the,continent together this is only on the on that side i'll talk about them temporal is that,social i don't know if social is actually somehow useful is there is there any reason why social it would be helpful in deciding if a bug,is a duplicate or not the you will be all other the the what i mean we can use it but it would be nice to have some reasoning,why why this would be the case so the question that we now have of course,is the original and duplicated reports,really similar to each other so can,dissimilarity really useful and to answer the question we perform an,experiment we selected the bug duplicates and we computed the ranked list of hundred most similar bug,reports andrew cold it's if this similarity if the the bugs are similar then we would expect the,original box appear high in the list and this strength this this is a slide the graphical results this curve here shows the number of detected bug duplicates if,we check the first kay top ranked results and we can see that,if we just check the first the most similar bug reports that we can,already identified thirty percent of bug duplicates if you go and check first five reports can identify forty five percent of the pickets it's in my opinion is quotes surprisingly good results because you,have to keep in mind that we have two,hundred fifty thousand reports that comparing,with and the to get thirty percent of the by but looking just the forces out,it's i think it's quite good so now the question is how can we,improve this ranking one idea that we had this we consider,using the meta information so as i showed all the reports are assigned to a,specific product and a component and the question is can we use this,information to to improve the ranking end we can see that if we use the product,product information we somehow again about five percent,however if we use the component information we even get the lower accuracy and the reason for that is that many of the users assigned the incorrect value of the,product or incorrect value of the,component and the reason for that is that the very often products are somehow,related so maybe sum product is a,component in some other product and the user then,doesn't know which each of this component is x actually,responsible for this issue all the all o the people the they you just get a flat list of names believe that these there's a structure but we we hope that,we can induce somehow this from the data so we can do this by looking at the duplicates so if we change the and,that wonderful one original but let's,say using product they and the duplicated reports in,productivity we can somehow create this relationship and this is one of the things that we,plan to do in the future so we plan to expand this list of bugs that we look at so instead of just looking at,box the same product we just also look at,the box with related products that might i have system so i guess we we don't get this,misclassifications that we get now so,ten percent the kids that we now miss we means because we simply ignor other products so this ten percent means that ten percent,of all of the box were assigned to different different,product well you about the the information but rather than right now it says that if we only check the box in the same product is that is,that there's a but then we can we can get this line that we get on top that long it the data is was that it can somebody doesn't help as much as,we would expect because you have this,misclassifications of of products now but relationship my the might improve decide differently the next thing that we really call will,improve the results that we haven't implemented it is using,the time information this is a graph that we obtained by checking it what's the time difference between the,original box the but the pickets so we can see in the graph that in most cases the original bargain duplicates duplicated biker reported very near in,time cortices makes sense because probably when somebody um and somebody commits some news sources,which introduces a new but and everybody,starts having this bug issues so that's why,everybody stopped supporting it and,that's why we get a high peak very near in time so the idea is that we can rank ah this list of of box based on the time,difference between box i the future work so i showed to the possibilities of using,methane formation another option that we are considering,set well very often happens in bug reports,is that people use different terminology,for the same things so people can talk about a,dialog early in the war on form but actually this this is the same concept that's,underneath so what we plan to do is we then to transform these different words the concepts that these words present,and then have this similarity computed on this,concept and not exactly the words and one possibility is also using this,relational learning because the mississippi the semantic in this way it's issue very very specific that's why we are,building this ontology this why building,this annotation ontology which will contain all this,computer science terminology and you have disconnected concepts and also for each concept you have all,the terms the which is which are the names of this,concept this first just as an aside you know that you understand what the in the feature space that if you don't understand is that you are we used in think now and you have some issues with the getting the results and the question what is that new maybe users so who raided the well we we can i am we can get a full list of of report,because you the we show you of course i of course but we should not be the user this whole,is but you should get some short it's present o it's essentially you we propose to do that of some parameters by and u so essentially the same ranking exactly all the but also among the wickets physically,among all the others forty also these we check among all the all the others exactly so there is so it's also it happens that it's not you don't always get just the original,block and one duplicates condensed,several duplicates this one original block and that's why i also,want to compare with other possible uses which is exactly so this well my well just speech plus minus some of the the problem is that here this see the it is a distribution which has been here,with and you it's piece so you can frequency it's a possibility but i'm not sure it would be make sense of the solution right on the speed is not an issue here the not point another thing is that there are so many the and here very right and the child this where use this is something that we can compute,right this happens since since this i assume that might help you to so order some these because you can also see i of and we try both the things because the number was hundred has been one the to show i want to know thirty six percent sixty two yeah i think that was because we don't want,users simply because they and and so what was already there and i think that also explains why that could result the because the users don't share it's the same the things you'll see the what you these the result the the most of because uses to see something's wrong with the screen and do,something and they also go through what is the one check don't the more delicate but probably check if there already is about i'm just common so this would be true if,you have some box which are very very often reported right yeah that know i don't have slide there before but,they can be here and show that this this is the distribution of of this this case so in ten thousand cases we have only the original bargain one bug duplicates,in three thousand cases we have one,original back into it you see this,distribution was very few seconds so it's not often that it happens that,you have the one bargain millions of duplicates on,the same by the is and i would expect school the you release i want do word again the only thing the the the other thing is that it's and maybe this is the case in which that's,why they have such a large percentage,points because the users you users that can be shown the submit but the exactly the well according to the united nations in,the world let's see what is really going might be do thank very well i want to leave one with the the information with the we really the problem is how i mean it's exactly because of the same,problem that really really really be three what matrix this is a problem because you is a very,specific uh and for that it it's a very weak thank yeah but i think this is the same issue,as i was describing is and why the,classification problems it's not a good option because this is a case where you have one,document and that you are looking the relation,with one specific document in the set of all of the documents and not to what,relation to this group of this specific documents about bodies pick it because it's it's related to exactly one of the either documents that is not in common this exactly this change the terms people who want to this is joint the new but this will exponentially increase the,number of examples where squared is two hundred fifty thousand all the i mean is an option but it still memory just to recognize if you the the he was one of the was just on the it all these the the and you i just everything you now we don't do so maybe maybe can use the you want to ask some and there is exactly this is this this is also one of the future stuff,that we and try and look at this that we plot as,the stock traces and then the somehow encoded assessment,information so if have the same,secretaries and probably it's more likely that it's the same,issue and if you have some something,completely different as we are not passing such as this is something one christian so two well i think is you which this movie features they should be the schools when the current u is that the you know more about the in deciding whether a bug is a duplicate,or not yet i would say that make information yes,but not for the features in the,continent because that's that's exactly the issue that we don't have these features which are indicative of about being a duplicate,not there are no specific courts that i'm more more often appearing duplicates than in non-,duplicates now that we have i mean like the second order the first order logic would probably be good because we could say that we would,expect to find something like about above but if x is duplicative there's some but,why it's similar in similarity between x and,wise about a certain threshold and time difference between x and why is such and such is also you can see a horn clause which makes sense and i the is probabilistically and also again it's,it's it's not an easy it's not only is it possible that you so on the surface so when all right and the same see these reports of here because on heart and just as well all and about so too often appears to be similar but
i want to say what a pleasure it is to,be able to give this talk this is such a exciting audience be,able to give a talk [HESITATION] so my work is as michael,said kind of at the intersection of machine,learning and robotics [HESITATION] makes a little different,and maybe some of the triple ai members [HESITATION] although,course people overlap those areas and it's it's,an interesting area to be [HESITATION] on the bad days i,think [HESITATION] my robotics colleagues think he's just a,machine learning guy and my machine learning colleagues like,out he some roboticists works in our area right and the good,days i think this is really the place to be right at this,intersection because that's where good problems are,generated [HESITATION] you know it's particularly pleasure to be able to give this talk,today as we celebrate shaky and i think take,is kind of the canonical example of the benefits of looking at,multiple disciplines and ai at the same time and if you look,at the research that came out of that particular project it's,truly tremendous and i encourage everyone to go to the,celebration tonight [HESITATION] and i just think about all,the things that have come out in terms of motion planning,[HESITATION] perception so on and so forth because of this kind,of interaction between robotics and the rest of ai so i'll,start the the talk kind of in earnest by talking about the,rise of learning machines [HESITATION] and so the the point i'd,like to make [HESITATION] is that i would say in the last decades,of in fact the number for about a decade,there's been a tremendous change in the role of machine,learning within robotics [HESITATION] so i would say a decade ago it was pretty rare to see fielded,systems that used machine learning in a kind of critical way,[HESITATION] you see some in the lab should really see them in,practice and now i would argue that that's almost,totally reversed if you look at the time the systems in,practice they almost all involved machine,learning often some critical way and so i'm just showing a couple,examples some car wellington's work in the upper left corner on,tenement autonomous agriculture and that's an area where machine,learning is playing a safety critical role in preventing the robot,from doing something wrong i'm showing the really stunning,way work about a coats and peter beale my bottom right corner,on learning how copter acrobatics by taking,advantage of humans right human imitation learning as well,reinforcement learning and i think that's one of the areas,where they really took a leap forward in what,was possible by taking advantage of machine learning,and of course our friends google as well as lots of other places,at in looking at a thomas vehicles and commercializing the,technologies that have been developed over the past two decades on,[HESITATION] autonomous driving and taking advantage,again a machine learning kind of the critical way and so i just,to point out something interesting anecdote about [HESITATION],the rise machine learning last decade we we had all the faculty,members the robotics institute there's a fairly large problem,the order of fifty [HESITATION] faculty members,[HESITATION] apply tags to their names as to what they worked on and the,single most common tag more common in computer vision or,perception or manipulation or anything else was machine learning,that's the single most common tag for people who work in,robotics and i think that says something about,how the rise of learning machines how things have changed,[HESITATION] so i think the most natural talk i might,be able to give me to tell you something about how machine,learning is influence robotics this kind of a invasion of,machine learning techniques in robotics but i think it's even more,interesting to look at really the interaction interplay and,how robotics influence machine learning so that's what i'm,going to focus on [HESITATION] so i think when people,think about machine learning and its influence on robotics or vice,versa i think they tend to think about things like perception,and vision i think that's right so if you look at,examples like in machine learning you'll find that things like,image net are now kind of benchmarks these kind computer vision,benchmarks are how we're judging machine learning,algorithms i think that's a very exciting area but there's all,kinds of other aspects as well so i want to start out by,pointing out that a particularly important area within,robotics in understanding for instance three,point clouds or to the images or the combination of pretty,pointless into the images is the idea of classification in context the reason they were able to understand,from three d point clouds that that particular thing that,i'm showing you is a tree trunk not a telephone pole is,because the context of the vegetation above it and similarly if i,show you a camera image and i show you a distant car the reason,you're able to recognize that's a car and not i don't know a,person is because of the context of other cars,in the scene the road surface beneath it this kind of,contextual reasoning is really crucial in machine learning,view of these kind of things to think of them as what's called,structure prediction predicting multiple bits at the same,time and i would argue that the needs of,understanding three-d and two d data have dramatically,driven forward what's possible in structure prediction if you,look at ten years ago structure prediction algorithms that,were available for things like max margin markup networks they,couldn't even fit the point that i'm showing you on the right,in memory right let alone be able to learn,efficiently with it and so that's i think radically changed,because of the needs of robotics applications i think one of,the most exciting areas that's coming forward in perception,computer vision and robotics is the need to handle contextual,understanding in streaming data looking at video and that's a,rising area that's pushing forward what's required,from the machine learning community and i'm showing here some work,by daniel moon us on looking at streaming examples have,seen understanding and so what you showing you here is trying,to classify every pixel in a scene into different classes based,on not just a single image but based on,temporal data and the improvements you get by looking at,temple data but does algorithms have to be streaming algorithms to be,able to keep up the data available to them so those are,just some examples of where i think robotics has pushed on,machine learning community but i think there's lots of them let me,give you another one that i think is particularly important,has been driving our own search robot perception has a really,important need and that's the need for speed so just to make that concrete think about a robot,that's moving sixty miles an hour ok and imagine you have a,fast machine learning algorithm fast by machine learning,standards and it can process i don't know one image per second right,stuff pretty fast for machine learning or that robots just got,eighty eight feet from the time the image came into the,time the planner get some information that's just totally,unacceptable from robotics point of view you can't take a second,per image to be able to do something and so what we've looked,at recently i'll give you some hints of the kind of ideas is,how do we take ideas that are coming out of the ai community,and so you're very jealous of [HESITATION] my colleagues,like max like a chair and [HESITATION] james copter who look,at any time algorithms for planning right so that's been a real,breakthrough in robotics planning side so again connecting ai and,robotics we want apply the same ideas in machine,learning we need algorithms that if you give the,more time they get better but they're able to give answers,quickly before the robots on eighty eight feet,ok so this was really inspired by work that,came out the computer vision community in particular by henry,schneider in cayo cannot a pavillon matthew jones on this idea building cascades so,methods that can look at an image and throw away large parts of,it very quickly because otherwise if you want to for,instance effective faced an image there may be a million ten,million different places you have to look at even if you spend,one microsecond on each patch of an image it will take,you will whole second to find faces an image which is again,kind of unacceptable performance and so what we've looked at,recently is this idea of any time prediction so,machine learning algorithms that test time you can give them a,computational budget on demand polen answer from [HESITATION] give me your best guess as to what's,going on and the kind of fundamental ideas behind,these are based on things like boosting and some modular,greedy optimization ok so for those who are familiar with,ideas like this think let me give you a little hint of how,such algorithms could work ok so in a boosting method you're,typically building an ensemble of different predictors,[HESITATION] and we usually think of an ensemble of [HESITATION],simple things like decision trees ok so we can augment the idea of a,weak predictor by its computational cost and ai,computational cost may be driven by for instance how complex a,decision tree is but it may be driven by what features that,executes or may be driven by what fraction of an image is willing,to work on okay all those things can affect the,computational cost of some learner and so the question is,how do we be efficient with on samples of these weak predictors and so out scrubs former student of mine looked at a kind of family of algorithms,called the speed this family of algorithms and the idea is,very simple what you do is you build an ensemble of,learners by looking at what weak learner could i,add to my ensemble plus in how much will i add that weak,learner in how fast will that drive down the risk,function the statistical risk divided by the time it takes to,compute that we corner so that's the central idea so in,pictures for those are familiar with boosting we,often think about boosting or forward regression methods as for,instance finding the weak learner that i could add that would draw,ride the risk down as much as possible so give me the best,we've learned drives the risk as much as possible what i'm,suggesting is an algorithm instead drives down the,risk as quickly as possible how much risk divided by how long does,it take to achieve that risk ok and i think that's a very,natural way to get an algorithm which is any time,it's an ensemble of predictors the longer you give it the better gets,and it's very much time aware so it turns out that it's not just,a kind natural approach is actually things one can theoretically,say about these things so for instance for this particular,[HESITATION] algorithm i just described you can say things like for any predictor that makes a,prediction using the same [HESITATION] based on the same features right the,same weak learners at time t'ao any other ensemble of the,same teachers couldn't have done much better ok so couldn't be couldn't have done computationally much,better or rather statistically much better where much better depends on,both the regular izations as well as smoothness of loss function,now if you want to apply these ideas to things like computer,vision what you'd like to do is leverage the fact that if you,wanted techtv equals for instance this part of the image is,really easy and this part is actually heart needs,additional work and so how do you do that no idea is,pretty simple you think about weak learners where the,weak learner is basically paired with what fraction of,the image it's going to work on ok and so the the the image,is going to be part the image are going to be ordered by how,uncertain that particular part of the images and,some weak learners may look at five percent of the in some,we've learners may look at fifty percent the some we cars we,look at all of the image ok that's the kind of,computational cost of a weak learner ok and then what we can do is look at if,we run this kind of speed boosting approach i describe what,is the resulting algorithm look like and so this is a kind of,[HESITATION] [HESITATION] give you an intuition for,what's going on so what i'm showing you here is at the,prediction times of one millisecond two milliseconds three,milliseconds formula second so on and so forth how much,computational effort has been spent on every pixel in the image,ok and what you see something very natural which is the,parts of the image that are quite easy so the kind of blank area,where there's road very little computational effort is,spent in the parts the image that are complicated lots of,computational effort has been put in ok which is kind of you,expect [HESITATION] in fact the lower right,corner actually has a reflection of a car which is why it,spends a significant my time on that looks like there's nothing,to you in the image [HESITATION] these methods are very,different than previous methods like cascades in that if you,give them infinite time they will visit every pixel infinitely,often right that's the at least in the limit,as you learn an infinite series of [HESITATION] weak,learners but there are also able to provide,answers that are better and faster than message cascades so it,gives you the flavor of computation prediction time,computation in machine learning how that so,important in robotics but i think maybe the most exciting,areas for [HESITATION] machine learning,robotics is actually learning to make decisions not just in prediction,side and so what i want to take you through,is why there's a difference between,learning decision making or learning control then there is in,traditional soup revised learning how to these kind of problems,differ and i think the very simple this problem,i can think about for learning decision making is the,problem of imitation learning and so let me take you through the,problem of imitation learning [HESITATION] of the kind of classical,reference on this would be dean palmer was work on,autonomous driving using a neural network and the idea is,very simple and very natural which is will learn to,drive a car by taking a crew camer image and,learning to map that crude camera into steering angles and we'll,train that by watching a person that's the the very simple idea,is that this is one of those really amazing papers that i,think everyone community should read even though it's a quite old,at this point there's all kinds insights into both,learning imitation learning problem and how to,make things practically work and this is been tremendously,influential paper both and learning as well as in robotics right so,i want to take you through what goes wrong if you think of,this is a supervised learning problem [HESITATION] given i'm,going to take you through what goes wrong i'm going to show it to,you in a video game as opposed to driving an actual car,[HESITATION] and so what i'm going to show you is learning,driving the tation where the input is a camera image meaning,screen capture of the game and the output is the,steering angle or joystick man that a person will provide ok so the,traditional so provides learning approach to i'm trying to learn,to drive for instance would be you watch a human drive,[HESITATION] a teacher drive the vehicle play the,video game and you collect the data set which looks like camera,images and the human steering and make a big data set of that and you,handed off your favorite supervised learning algorithm so for me,that's linear regression maybe for you it's a deep convolutional,neural network whatever you like and we handed off to,the learner and we get out some learned policy and then we,apply that policy that's kind of the canonical supervised,learning approach and it's interesting to look at what,happens if you do this so this is stuff on ross a former,graduate student of mine driving [HESITATION] super talks cart,racer videotape stuff on is [HESITATION] pretty good at,this you might argue he's disturbingly get this,[HESITATION] so you let him do twenty laps or so and,then you handed off to [HESITATION] a a unit office rote,learner and you let it drive and it doesn't work,very well right so [HESITATION] came over have we,have really we made no progress [HESITATION] know,what's going wrong here so there's multiple answers that one can,naturally come up with i think the first thing people,think is have you use some poor set of features,or some or we learner right your linear regression wasn't good,enough to solve the problem that's a really natural answer,[HESITATION] it turns out i can tell you that's not the,problem in this particular one linear regression perfectly fine for,some from ok i'm people's next guess is they,say [HESITATION] maybe the problem is your,overfitting so you've got good performance in your,training data but you've got bad performance a holdout,data and so you you're driving isn't very,good but actually hold that errors here very close to training,years so that's not the problem either from is,actually more subtle and one the dean pointed out,[HESITATION] in his work that was describing earlier and the problem is that when we are in,the imitation learning setting the predictions we make a fact,the future inputs so the steering angle you you choose,affects the camera image you see next ok [HESITATION] and so,inevitably what happens is the learned policy isn't perfect and,it makes errors and it sees camera images which are from,a different distribution than the training data was from and this,immediately violates the fundamental assumptions of,statistical learning theory which is that our training data and our,test data are independent samples from the same,distribution in fact are not from the same,distribution at all the training data comes from the teacher and the test data comes from the,execution of the policy itself right so these are in fact quite,different distributions and the result of that can be quite,different distributions and the result is interesting so in a,supervised learning setting if i ask you to make t predictions and i,told you that on average you made epsilon classification error,right you would expect to make on the order of,t epsilon errors right very natural ok in imitation learning,setting unfortunate that's not what happens what happens is you,make something like t squared epsilon errors and the reason is,very simple if you make an error it's very likely you'll,end up in a new situation could be qualitatively different than,anything you've seen before and you'll make a whole string of,errors from then on ok and you can think of t is a proxy for,something like horizon length of the problem it doesn't have,actually be t actual decisions the mixing time and so we had,this thing that should really disturb us as,machine learning people which is we have low training or holdout,error and we have actually poor test,performance so what's going on there so again coming,from robotics point of view [HESITATION] lots of problems,turn out to have this flavors so if you think about system,identification optimal control from a kind of ai point of view,model-based reinforcement learning you see something that's,remarkably similar so imagine we want to for instance learn,helicopter knows in function so to move like this very easy,for a computer relatively hard for person [HESITATION] how do we,do that so the kind of textbook method control,method for doing this is and this is literally from,[HESITATION] where young's textbook is we have some way of collecting data,and exploration policy you can think of as a human injecting,some additional controls to explore the space of states of the of,the helicopter so maybe they execute those in final,themselves we collect data we fit a model so,maximum-likelihood whatever your favorite model fitting procedure is we take that learn model we apply,optimal control synthesis with some cost function that specifies,what we want to accomplish though the particular maneuver we're,looking at that cranks out of policy and we apply,that policy ok so this is what happens if you do,that [HESITATION] [HESITATION] on this is a,helicopter simulator from peter so we have the human fly around like,data and [HESITATION] we're going to use that,data to build a model to them wrong an optimal control,synthesis algorithm try to do the same task ok and looks promising at first and then things,go wildly wrong ok i'm not so good [HESITATION] the,interesting thing you'll know is that engineers worth their salt,don't actually follow the procedure i just described as the,textbook procedure which i think is worth noting so why does this,happen so the reason it happens is because we,we've collected data from some exploration distribution and,then we apply when we build the model we then apply this,optimal control synthesis or think of it as a planning algorithm,on top of that model that planning algorithm will inevitably,explore states that were poorly sampled during the the,model building procedure [HESITATION] and in fact you should,almost think of the optimal control synthesis algorithm is,adversarial ok [HESITATION] so chris actus in,[HESITATION] one by the common to me that the best way to debug your,simulation is to run an optimal controller on,because it will very quickly find and exploit any bugs that are in,your simulation ok and that's exactly the point here the,planar will actually exploit bugs in your model right that,are not the way the helicopter actually works to try to make the task a,cheaper to perform ok so again we have this very,frustrating problem that we have a low training our model we,have a good optimal control synthesis approach and yet we,get that test performance right helicopter doesn't fly so i want,to point out that these kind of problems that [HESITATION],describing that are rising control and robotics are really,foundational issues from machine learning right this is,questioning the way we really think about supervised learning,right what's the right framework to think about supervised,learning ok and it it bears on that there's a set,of tasks that we think of as i id supervised,learning tasks that we can learn well only from examples and,then there's a whole set of tasks of which i just mentioned,to imitation learning [HESITATION] system,identification but there's others approximate policy iteration,optimization prediction of lists which can't be learned well it,turns out using only examples and the question is can we do,better and the answer is yes in fact it's,actually in some sense very easy to do better once you recognize the,problem ok and so what is the main problem of,the main problem is are we think of the imitation learning,settings are our learner doesn't know how to,recover from its own mistakes doesn't know what to do when it ends up,in a situation which is qualitatively different than what the,human so what makes an error doesn't know how,to recover so there's no training data of what to,do when the car gets near the edge of the road now it may,have some training data it just that that's a small fraction of,the data set signif sufficiently small that the learner will,often sacrifice performance on that to do with,better on the bulk of the data that's a very common kind of,failure mode so what's the intuitive solution well,into solutions to use interaction with the system to gather,more training data to fix the errors that were made so let,me take you through an algorithm which is a very natural,algorithm but also now [HESITATION] and we can prove some,things theoretically pain so this is a stuff on ross these,were the idea is what will do was first will,run straight supervised learning is the same picture i show you,before define drives the the super talk start,we collect data we applied whatever your favorite manner,is we get a policy ok but then we can do,something a little funny what we're going to do is we're going to,execute the policy that we just learn ok and we're going to,have the human provide corrections of what the learner,should have gone in the situations that show up ok so you,can think now that the data is coming in a very odd way in,that the images are coming from the policy driving and the,steering angles are actually coming from the human teachers and again we're going to aggregate that,together with the previous data we collected from the last,iteration ok well apply [HESITATION] supervised,learning algorithm will get a new policy and interestingly that,often works better but usually doesn't solve the problem,and so if it first you don't succeed try try again so we're,going to iterate the same approach where we execute the current,policy have the human provide corrections get new data,aggregate that together with all the rest and again apply supervised,learning so again apply [HESITATION] linear regression algorithm and will iterate that for some number of,iterations and hopefully good things will happen so in fact things do so for this particular,case i'm showing you the falls per lap as a,function of the amount of training data which is the,only fair way to compare algorithms you really looking at two,lines here the first is the black dashed line up on,the top which is the supervised learning,approach we're on just watching a human collect more and more lapse of,data and actually the performance doesn't get better as the,amount of data goes up in fact it actually gets worse sometimes,which is really disturbing that may be due to the human getting,bored right [HESITATION] the performance of,the interactive approach that you're seeing the number of lab is,actually going to zero relative number falls rather is actually,going to zero relatively quickly with the amount of,training data ok so the only difference between these two is,who's driving the car right the actual interaction versus not,interaction [HESITATION] from a from a from a kind,of a obviousness point of view the point is you can't learn,drive a car by watching someone drive a car right you have to,actually do it okay so don't for you can prove some,theoretical guarantees for this kind of algorithm to basically,say that if you run them enough it eration you will get,performance which is now again linear in the number of,decision that have ok and so what that basically says is,it's easier to think about the contra positive one of two,things is going to happen [HESITATION] you're going to the either,set up a learning problem one of these supervised learning,problems in the aggregate data set that's too hard to solve that,could happen it could be that you need more,complicated learner and you give the set of images in,steering angles and no supervised learner can do a good,job those rote learner in your second do a good job on class ok,but if that doesn't happen if you actually do succeed in,building a good supervised learning data set then you will build,something that's good at driving the car okay that's the the,only two things that can happen ok so i could show you a,driving around the track again again again but that's going to,don't so show you something more fun which is,applying the exact same idea to what we call the force of,indoor problem so for those of you who are familiar,with [HESITATION] the third star wars [HESITATION] there's,a scene where they go speeding through a forest so we want,to see if we could get a a aerodrome brooks known will toy,to go for speeding to the forest so we're going take simple features that one can predict,from camer images or sequences of camer images like,optical flow [HESITATION] errors corners very simple,fasc features and try to predict the,joysticks angles that a human is commanding and so i'll just show you,a few videos from networks it's kind of fun and you,can see the steering angles in this case the left right,steering angle that's being predicted as the system,tries to fly through relatively against forces and you can see that kind,of features it's computing so [HESITATION] [HESITATION] i optical,flow [HESITATION] various other features and,what you find is that this particular system even though it's completely myopic in reactive is able to,do about as well as a human can do flying through a forest,using the same forward-looking camera not quite as well but on the same,more good so the question is how do you,analyze the the kind algorithm just describe what's,the foundation i just said the kind of statistical learning,assumptions of independent training data don't apply,so what's the right way to think about these algorithms and,i would argue that there's been a beautiful series of work,that comes out of the computer science game theory community which is called no regret online,learning ok and it was [HESITATION] is designed,in kind adversarial non-statistical setting ok,so it's designed to think about what your data didn't,come from some distribution but rather it came from an adversary how,can you promise good performance and the standard claim of no regret is,that you want in nearly as well as the best hypothesis in your,class if you've got to see all the data up,front if you've got to cheat and you see all the data of front even if the data is being generate from,an adversary which by we sounds like a crazy,commission if you've never seen before in that that's completely,impossible actually turns out that many algorithms,that are capable of doing that particular task [HESITATION] i could explain the kind of no regret,set up to you but i actually think there's a simpler way to think,about no regret for the purposes of these kind of,control applications and the idea is that there's a,sufficient condition to implying [HESITATION] regret that almost,necessary ok and the sufficient can dition is that,no regret algorithms are learning algorithms that have the,following two properties ok they asam topically pick the best,hypothesis given all the previous data they've seen so far so you,might think about is [HESITATION] statistical point of,view as and how to consistency you give them a lot of data on the data,they've seen so far they do well okay that's kind of a,minimum requirement you can do that it doesn't mean you do not,doing something very good but they also generate a stable,series of predictions in the sense that if i if i change one,data point or i hold that one data point the prediction of,the algorithm doesn't change much ok so algorithms that are no,regret our acid product consistent and they're,stable ok so they don't they don't flip their,answers very quickly in response to just a single data point turns out those two conditions are not,to imply the no regret property and almost all no regret,algorithms have those two properties and you can synthesize one,does even if someone hands you want it doesn't okay so this,kind of approach is what lets us prove things like stable,algorithms plus a low training error policy with this kind of,iteration lead to good test performance ok and the,key thing i want point out is what doesn't work is things like,policy iteration which update a policy based on just new,data they collected each iteration okay those kind of,algorithm don't work at all all right [HESITATION] [HESITATION] you will spend much time to there are lots,of no regret algorithms what the canonical ones is gradient,descent on convex last functions but the point is that any no,regret online learning algorithm can be used in the iterative i,just described so i describe one recurrent aggregate all,the data together and then you learn based on aggregate,data set but actually for instance for convex,loss function like for instance square loss on the driving,angle you can just run gradient descent ok and,if you choose the appropriate step size you will have the,same guarantees i just described ok so low training area policy plus no regret [HESITATION] stability,ends up giving you but has perform mean good test perform,so you can apply the same idea in the system identification,framework so what does that mean we're going to collect data,now not just from the exploration policy but from two sources,the expiration policy as well as the current optimal,controller some beginning we don't have an optimal control so it's,just from the expression policy but after the first iteration we,have [HESITATION] proposed controller we're going to elect data,using that controller ok and we're going to take that set of,data which looks like a state an action next,state so something we can learn a transition,model from [HESITATION] or to aggregate that to get together,with all the previous transition we've seen we're going to,apply our favorite supervised learning method to for instance learn,the transition model so you can you might think of linear,regression to learn a linear dynamic system we apply our,optimal control algorithm so maybe something like difference,dynamic programming and we get a new policy and then we,iterate this we and every iteration we're collecting,data from both the expiration policy as well as from the current,proposed optimal control and it turns out to improve the same,kind of things low training or model plus a no regret,learner plus a good optimal control system will,lead to good test performance and i can't go into the details of what,i mean by good test performance it's kind of a relative,guaranteed the way you collect exploration data but the key,point is the guarantees are agnostic they don't,require that the real system being element of your model class and that's qualitatively different than,the way people usually think about [HESITATION] statistical,learning of for instance system identification right so here the,claim is just you have to have something that good,prediction not that the real world is one of your,models which is in general not a reasonable requirement ok and if,you run that approach it does what you would like to do which is it manages to fly than those in,fall one point out is that this is what real,engineers actually do so really engineers will iterate the,process of model building in controller synthesis and the reason,they're doing that is exactly to kind of explore the modes,better that aren't being explored when they,collect data initial so that's a it's a very natural thing,and so what i want to show you is that the approach i just,described of iteratively building controllers and learning statistical models based on,that gets performance which is basically as,good as if someone had to be the model in closed form to begin,with ok where it turns out that the kind of,facts just collect a pile of data approach no matter how much,data you collect turns out it never approaches the performance of the of the optimal model and it turns,out even if you collect data from the distribution,of the optimal controller if you were to cheat and somehow collect,data from the distribution of controller the still at ok so it,turns out that this whole series of problems that can be,learn by repeated interaction no regret learning which can be learned,only from batches of examples and i would argue that robotics,has really played a critical role in pushing forward these,kind of interactive learning is i think of work by,[HESITATION] and well of los a and so nature nova chat jenkins and,others on these kind of iterative methods for,learning for instance from demonstration and i think that is a,a real breakthrough so there are other differences between,imitation learning and [HESITATION] supervised learning and,i want to take you briefly through one [HESITATION] so one,critical difference is that in imitation learning we often,see very purposeful sequential behavior that,are important to demonstrate and so i spent a [HESITATION] amazingly,large amount of my time trying to build robots that can,navigate from point a to point b in really rough kind of,arbitrary output trains is actually very simple terrain,relatively speaking and the idea is you want to get a robot,to go from point a to point b point in point b are,separated by basically arbitrary terrain and maybe ten kilometers of,arbitrary trade between no way points in between how do you,build such a system and i don't think i have to convince,this audience that it's not easy to do that even if you robot is,a big tank looking thing like that because there's many,things that can go wrong so there are slopes that are hazards for,this vehicle if it hits a tree you could take a wheel off,if it hits a rock under a bush the robot could be damaged beyond,repair it has to think very carefully about all,the decisions it makes and it has to stitch together a coherent,plan that gets it from where it is to goal okay now the,interesting thing is that while it's hard to program that,behavior people are actually quite good my colleagues driving this,vehicle by hans got a remote control and you can get the robot,from point a to point b with really variable problem at all,much better than the state of the art algorithms so we'd like,to take advantage of imitation learning but i think i can,also convince you it's unlikely that my favorite linear,regression algorithm is going to successfully navigate this,robot from point a to point b ten kilometers,apart right that's probably unlikely to work,so what might be a reasonable strategy and,i think it's good to look at what roboticists have actually,done going all the way back to things like shaky which is they,think about the sequence of predictions sequence of decisions,that the robot is going to make as the output of some optimal,control algorithm right or some planning algorithm so what's,going to happen the decisions that are going to be made our steps,along an minimum cost plan point a to point b from that point of,view it perception provides information about states in the world,and planning shabazz to find the minimum cost path then,learning has only one to [HESITATION] which is it has to take,that perceptual data in turn it into costs described every,state of the world and that's in fact the only thing you can do okay taking advantage of the fact that,people can do this task sets up what is naturally an inverse,optimal control problem we know what's off behavior which is,what the person is doing person doing the right thing how do we,learn a function which maps perceptual data to costs so that,looks like the human is doing the optimal thing ok and this,idea actually goes all the way back to a pretty common he,looked at this problems if you had to be a linear controller is,there a cost function for linear system that,makes that controller all ok and there's been beautiful work,in this community i think in particular of stuart russell's,work on applying these ideas the general in the peace it turns,of robotics is really pushed forward this kind of state of the,art by generating algorithms that have both,regret are online learning bounds as well as generalization bounce at guaranteeing that they do they will,behave very similar to the imitation of trying to imitate,begin with ok it turns out also show you at the end which generalizations to noisy behavior,they're able to predict the behavior of humans so let me give,you just a cartoon example so a cartoon example of this very hard,to see is there's a red dot another red dot in,a human is asked to draw the robot from that thought that,thought and a person does that very reasonable,thing unites that is the driving on the road ok if i give,you that red dot in that red dot is a test example,most people think that what the robot should do is this which,is actually what the algorithm synthesizes in this particular,case but the reason it synthesizes this is,knowing about roads or what ever the reason synthesizes this is,it's able to interpret that camer image in this case over a,camera image and say that brownish dof is cheap and,the other stuff is expensive and that is what allowed my algorithm to,agree with the human in the first place ok if the human did,something totally different there's a stealth robot hide in the,canopy of the forest to get from point a to point b,the algorithm produces a completely different result and the,reason it does is it's changed its interpretation to think that,the forest is cheap the road is expensive and the grass is,somewhere in between again doesn't know any semantic,categories to these things ok i don't have time to go through how,these algorithms work they can be shown to optimize a convex,cost function [HESITATION] and they combine,essentially planning and supervised learning in iterative loop ok although,they are kind of fun to watch so that was the humans initial,path [HESITATION] that was the first guest,path of the robot and will slowly changed interpretation of,sensor data until it agrees that the human did the,right thing to get from point a to point b and it,turns out you can apply the same ideas lots of different domains like for instance legged locomotion this,work on the learning locomotion project [HESITATION] which a,number of my colleagues in room also had the pleasure working on and the idea is you want to sequence a,set of footsteps to climb across rough terrain almost,like rock-liked ok and again you can learn from people,what's the right way to walk across terrain ok but a point i want a to make is that,the ability to mimic also implies the ability to forecast,humans behavior and this is an area which i think is more and,more exciting robotics is if we want to be able to interact,with humans we have to be able to forecast the future on,observed actions so this is some work from a former,postdoc mine chris kotani as well as brines eve arden who did a,lot of [HESITATION] after this thesis and the idea is what we're,going to do is look at for instance a camera image like that and trying to predict how human will get,from that start to that goal with x right how they can,accomplish that task ok there's a straight line probably,unlikely to do that ok so why well you can take the kind of,structure prediction algorithms i described before and,analyze the scene in fine things like sidewalks in cars and grass,and so on and so forth and then from training data people,walking around in different scenes not the scene you can learn that,people don't generally walk across cars they,will preferentially would walking across a car they preferentially,go to the sidewalk they preferentially stand near curves,they would prefer to walk on the grass and walk over a,building and then you can make predictions that,look like this that this is the marginal density of,trajectory these that if there's likely to take and the robot,is i mean the person is taking the sidewalk their standing,near the curve there avoiding the cars so on and so forth as,a final example of this kind of activity forecasting or in,ten prediction i want to show you some recent work,[HESITATION] that i'm very excited about [HESITATION] there's been a real,revolution in [HESITATION] neuroengineering,recently and [HESITATION] there's been many many,people working in this area but [HESITATION] i tell you a,little bit about work by in these words and jens colander were,[HESITATION] two colleagues mind working overseas that's per and,what they've shown is that within intracortical implant so,works in basic procedure that actually goes in your brain they,can take [HESITATION] neural spike trains that,are coming out of [HESITATION] the brain and they can actually decode,what is the intended motion of a person's hand ok now,[HESITATION] in particular the kind of velocity of a person's hand and what this is allow them to do is,[HESITATION] essentially offered the potential for revolution in,prosthetics and then we can take a subject to the,quadriplegic ok and give them a robot arm where they,can control the robot arm by thinking about their own are,moving and this is one of these things that,when you see it in in in person it's truly magical right,they think about that are moving think about their own are,moving and the robot response in the same fashion okay so there's a,robotics problem which is how do you take the end effector,velocities in turn into motor torques it but that's the basic,underlying think now it turns out that although it's,magical there are limitations so they get limited degrees of freedom,what they basically have is what looks like linear,regression on temperley smooth spike trains trying,to predict and defector velocities ok they don't get the full,degrees of freedom of the robot arm [HESITATION] they don't,know anything about obstacles in the environment there's no way to,extract forces repeat this is from the brain right now okay so,things like grasping or really all about forces an impedance,is not just about positions [HESITATION] there's particularly,limited accuracy when grasping they often move very well first free-,space but does limitations when they get near objects this kind of,its own interesting [HESITATION] neural problem and so what,we've looked at is basically taking a fully autonomous,robot and making it less autonomous ok so a robot is designed to,do manipulation actions and have it commanded by human so the,idea is we're going to take this intracortical implants extract,the the motions that a person in tens and,then we're going to infer what they are intending to accomplish,and then do subtle modifications to try to help,them accomplish that task that's kind of the key idea and so,[HESITATION] [HESITATION] some of the key students,who work on this including living in catchment children's,i've done he actually in the room and i'll show you a quick,summary of how these ideas work so [HESITATION] the,first thing you would do is you try to predict given the,person's motions so the velocity he estimates that they're,making what they trying to do which objectively trying to pick,up it may not just be grasping is maybe,more complicated manipulations action is gives you the idea and then,you reason about what or the actions that you could help the,person accomplish those tasks with ok once you can do that you,can actually suddenly change the commands of the,person is executing to improve their performance in actually,accomplishing a task picking up objects ok you're taking,advantage of the fact that you of all of the machinery of a robot,it knows where the objects are an environment it knows how to pick,up objects it knows what forces to apply to,accomplish tasks and the real problem is to figure out,what the person is trying to do and then suddenly modify the,commands actually accomplish those tasks and i'm just showing you,some examples here [HESITATION] with a subject one of these,intracortical implants and comparing the direct control the,robot versus a computer assisted version and [HESITATION] the no,assist doesn't look particularly good here this is not a,particularly good day for the patient [HESITATION] but the,computer-assistance basically makes the human able to perform this,test which is actually a test for stroke victims which,basically count how often the person can pick up in object put it in,the air and move it onto a surface they can do that about,ten x vaster than the system without this kind of autonomy,assists and the changes are relatively subtle,just suddenly adjusting what the human is trying to [HESITATION] so this gives you a flavor but i want to,make it clear that these are not only grasping tasks i'll,show you some more exam this is another example this test is,called a rat it's a stroke we could test [HESITATION] but you can,actually do other things too like you can enable of person to,open a door and why because you can recognize that,the door handle and you can recognize the forces that,are necessary to open the door but not ripped the door off,hinges ok what kind of force emotions are,necessary to do that even if the person doesn't have control,of the angle axes the robot maybe they have x y z control you,can still recognize when they pull down the door handle,they're trying to open the door right pull down pullback ok,[HESITATION] it doesn't have to be in in [HESITATION] these,objects in isolation perfect robot world you can also give,the robot a kind of cluttered seen in a can infer what are likely,grass points that a person could be trying to,interact with ok and then let the robot kind of take,over those cases ok so just to [HESITATION],finish the discussion of [HESITATION] decision making control,i would argue that robotics at a tremendous influence on,reinforcement learning as well particularly in the rise of,policy search methods i think some of the work coming out of the,triple-a i community on robocup it's a good example on,building in domain knowledge and then optimising the performance of,policies built on domain knowledge in the real world,and i think the idea of model based methods and in particular,robustness to under modeling is a major area were,robotics contributes to machine learning research as well as,well as the critical role imitation and so i'll conclude by saying that i think as we gather here,triple ai i think it's really important to look at that,cross-disciplinary efforts right the areas where different,subdisciplines of ai can work together and i think that's why i'm,excited about the things like the the effort going on here as,well as the shaky celebration as it gives us a chance to define what,the good problems are i would argue good algorithmic research is almost inevitably driven by real,problems from some other domain and i would say,that robotics has been consistently and reliably one of the,best generators are real problems for the ai community for the,last several decades and will continue to be so thank you,very much very anybody yeah i know it's very interesting so i,think there's [HESITATION] i think there's a lot of interesting,relationships between these methods in active learning,[HESITATION] it's not explicitly there's no explicit,information gathering these kind of methods right it's just,trying to do its best and then getting,corrected [HESITATION] but but there's actually in,even deeper connections i think it's kind of interesting one of,the major problems in both theory and practice with active,learning is that one year in active learning you,choose the examples therefore of the distribution of,examples that you see is radically different than the,distribution of examples that you'll get tested on because you chose,the examples from whatever distribution you wanted,not from the distribution of actual examples you can see it has,time so active learning actually face is,exactly the same problem that said i think that this idea of,interaction interactive learning in general encompasses both,these kind of iterative methods [HESITATION] describing as well,as active learning approaches and i think things like,imitation learning can certainly benefit from both yes there's in question [HESITATION],mean kind of inferring a person can right now i think it's,interesting to the algorithms described it turns out,the ones were looking at actually inferred not just in,principle in for not just goals but actually in for folger,jectories as well but you would have to of course you,could work in extraction you only in for the actual objects,[HESITATION] and in this case if it's only using the,inferences about the locations on the objects not not,trajectory is that [HESITATION] use [HESITATION] i think very,interesting how do you manage that higher and higher is a good example,of something which is absolutely essential in robotics,right so i gave you this kind of cartoon picture robot getting,from point a to point b right but in reality there's a whole,hierarchy of planners that go from low level control of the,wheels all the way up to the kind of,abstraction i just described so i think hierarchy is a good example,of something that comes up in making practical systems work that,should challenge machine learning how we had we use that [HESITATION] that's a great question yeah that's great question so the,assumption here was that the human is doing the right thing just,to that of course in reality i know what i,want the robot to do is not fall off the road right and so,your right one of the most exciting areas is that interface,between imitation learning rate learning [HESITATION] meaning the,robot is learning how to do things on its own kind of interesting if you look at the,at least naive theory the naive theory tell you that the only,thing that's useful to learn from a human is what state it,spends time in action just completely ignore of human does is,actually what really matters is the states,expense [HESITATION] [HESITATION] that's i think a little,counter intuitive so i think [HESITATION] that's a good,challenge for machine learning is how to bridge,the gap between imitation learning and reinforcement both in,theory and practice yeah [HESITATION] in this particular,setting the the the less sure the system is,[HESITATION] the more subtle the control authority,that it provides is and so [HESITATION] either either,because of the way it solving kind of the optimal control problem or,by deliver heuristic if the person poles back right we're,search removing directly towards another object people realize,that's not the right right so that that arises either because,it's built into the system or because of the nature of the,intent inference that you're moving away so certainly can make,mistakes [HESITATION] in fact one of the videos basically,human calls out which object to pick out so it the test or the,experimenter i would pick up in the human then the,the subcaste a pick it up and the system can make,mistakes along the way they just get corrected [HESITATION] yeah representations of,difficult thing [HESITATION] here the,representations were in some sense hand code it because they're kind of,features that come out of the environment or perceptual,features that come out of the environment there's a representation,of what the planners reason about to write what is the kind,of state-space of those planning algorithms [HESITATION] in this case the states,cases are all manually designed [HESITATION] the features are,either manually designed or they can also be learned in some ways,as well but but a large part of the kind of,representational part here is [HESITATION] [HESITATION] human,domain expertise i don't think there's a reasonable way,to think of these kind of imitation learning problems as having [HESITATION] hidden markov structure,right because [HESITATION] that there is temporal,dependence but that's not the issue [HESITATION] i'm concerned,about not worry about that temporal depends we could we could,subsample the data one every so often one over t steps and,remove that temporal dependence not the temporal depends them,particularly worried about it's the fact that the controls,actually affect distribution right so i don't think you can get,around this kind of fundamental need for interaction by a i'm just,looking at the kind of temporal structure so for instance in the,helicopter case right it is in fact learning a time series,[HESITATION] all right it's learning a dynamic time-,series model [HESITATION] so it it still there's no,way to avoid interaction so one of the results as you can prove,that you can't solve any of these problems better than some,level without repeated interaction right so know who know who
right i'm not going to become a phd student of,a full-scale university in the next minutes we were talking,about supervised learning of graph,structure so first of all why do we need to go from either the,presentations at all we need to be the presentation because,basically they actually stand for from a,number of problems that goes from,chemoinformatics to procure makes in,computational biology genomics say that to mine in computer vision and complex,systems so let's take a graph with the way to model a lot of problems and they have some advantages over,future based presentations for example in a few we can graph can,capture relational arrangements between,the object primitives whereas the key to bayesian,decision kind and then of course he has the ability to,capture relational arrangements can pass providing contextual information two an in part the identification and also grant money and of course the,transformations such as change of scale,change of viewpoint all three computation just,to name a few the probability that thing is that most,of the time the pattern recognition,techniques as you know work on victoria space so they,are hired to input but the problem with that is that we,cannot easily embed them into victoria,space and there are two reasons for that,because there is no natural ordering of,nodes and edges of the graph if the set of,that if you know if you want to establish and an ordering of the,nodes we have first to establish,correspondences between these graphs second even if we are able to establish,correspondences and met the graph into a vector then due to about due to the viability,of the nodes and edges number the graph on the same in and the,director of the same so something quantities such as mean and,covariance are not easily characterized and then we know that we are not able to,easily summarize our object to using these quantities to be said to,have been so successful attempts at,embedding graphs into victoria spaces for example approaches based on spectral,decomposition of graphs but these approaches are not able to do,is to characterize the motivation of the set and this is actually what we want to do,what want to do is thing is given a set of an undirected,graph the training set we want to learn a,generative model can describe the distribution of the,data as well as the structural variation,of the set we make an important assumption which,actually is not the matter that much,important you would see that later which is that we want to learn mixture,model which is a mixture of these models each of which is working under the,assumption that the edge and node observation not,independent of the others each model is composed of two parts the,first part of the structure of which basically because the number of,nodes that the model can generate the,number of possible edges the queen and the three,kinds of search and the reason for stochastic which includes the viability of the,observed sets so for example we define a binary random,variable which covers the possibility to,to observe and another or not same for the edges but of course for the,edges we have condition probability on the presence of both the endpoints of,the edge and we may as well defined and model for,the attributes on on all edges this is a simple toy example we have this is a complete graph with three,nodes and the edges and each node and edge is labeled with the probability of,observing or something that no edge and these to the right is the of the,possible graph can be sampled or observed from this model but i want you to notice that usually,when we when we observe this data we don't we,don't know the correspondences between,the originating models and the sample graphs so,distribution that we actually observe is,the one to the right because of course we cannot distinguish,between the second and third graph here the mothers a few limitations the most important,thing is that you may have noticed that,the number of nodes that our simple graph,that is can be at most to be the size of the graph of the model so we,can see that our model is descriptive rather than the predicted and it's also means that it has to,encode all the structure that we observe in the data including the noise and this,is something that we don't want so what we do is the following the model,described so far is defined as the core model but then we also want to be able to,generate external nodes outside his,mother we do this with the following geometric,distribution and y for the edges we defined simply binary random bible,telling us if there is an edge,connecting an external or not we do the same for the attribute of,northern edges of external the links is we define some generative model and so somehow these external nodes,represent the knowledge that we don't,want to model with the core of the OK so now we may be wondering what is,the probability given this model of uncertain graph,first of all i want you to notice that these said before once we lose track of the,correspondences between the the this simple graphs and the,generative model we somehow got observe different distribution so we have to say we can model this by saying that random,mutation has been applied to the nodes of the sample and then the observation of the actually depends not only on the,generative models but also on the set of correspondences,that we defined between the centre graph,the generative models so once we said that the probability of,observing the graph given to more than set the first responses this is,basically given by this formula where we exploit exploit the fact that we used,that independence assumption OK so now the problem is how do we estimate correspondences typically we could do graph matching we,can use graphmatching approach which means that we selected is the set,of correspondences sigma said that,maximizes the probability of observing the graph given well the g in the set of correspondences however this simple example example,shows this in induced by bias in the model estimation,a single correspondence estimation in,general in this bias in the model estimation in fact since these is the distribution of the observed the,model the queen that we learn about by maximizing the probability and doing,just one estimation of the,correspondences is this one which is not the original so what we can do instead of maximizing the probability,thing the expectation over all possible,correspondences unfortunately averaging over all,possible correspondences is not possible,due so the space and so what we do is we resort to an,importance sampling approach has the right to sell in two thousand eight and,this means that we compute basically,compute a fast converging estimate of this probability OK just briefly how the the,correspondence and what we start from an,initial guess for many shows from initialisation of,the metric of correspondences that we,call and we iteratively sample correspondence,and then we condition the metrics and to,these samples we do this several times and here we get,a complete set of correspondences OK so once we are able to establish,correspondences to sample the,correspondence we can expect to estimate the parameters of the,nodes edges and attributes and what we do is just taking a simple,maximum likelihood estimation approach and what we can do it and it is what we,actually use the independence assumption we can maximize the likelihood of the log,likelihood of the model of each node,that separately because of the independence assumption the model first of course is to be dependent on,the initial choice of so what we do in this work is very,simple and we put my age equal to the probability of the null,model i of the model to generate the attributes,of the graph h and what we do that is to find these,magic and by updating it with the rule after the first on the same,thing with the following shown in the slide so summing up we initialize the model the metrics for,example the binary and parameter which,describes the possibility of this being an old or edge we shall is the model and the metrics,and then we repeat the learning process several a fixed number of times we simple if you correspondences it's,set of correspondences and expand the,simpler correspondence we can have observation of nodes and edges,to the model so after this can be the parameters,using the maximum likelihood estimation,is shown before but in the beginning of five issued a,recall i say that i wanted to make genetic model not noticing the,generative model and i said so far so what we do is we,start with the side mixed with a lot of comments and a lot,of knowledge and we iteratively learning the model and try to run it in the best what does the best way meanings case,where we follow the approach of,o'sullivan out of two thousand eight in adopting a MML,minimum message length criterion but this time used to guide the pruning,technique so briefly if you don't know how the,minimum message length works we can say that simplicity is formalized,as the joint cost of describing the,model for the data and describing the data,given the model so this actually translates into about,message shown here well he is the number of parameters of,the model and thus become idea is actually the size of the same sample set so what we do is saying is really,choosing the action learning action,actually we can be removing images accompanied or reducing the size of the graph the pruning action we to maximize the,reduction in message length and in order to what we do actually it's,bit of my thing in order to compute actually must have been in,message length incurred when we remove,the node we need to know what's in,correspondences we compute the matching,probability not only the current product but also of the current,model without so we keep track of this information and in the end we use it when choosing,the best pruning action OK but you have to something say,anything in particular because you might,want to the generative model this which is the,best so what we need for modelling our,attributes in this set of expanding,experiment i'm going to show you is for the node we use,the rectified gaussian model one by one percent hancock in their,their country unions quite simply we have a single stochastic,node observation model x we sent these and if the sample is greater than zero,then the node is observed and we the way people into the if the on the other hand on the other,cases the does not observe the talk so the probability of observing a node,is equal to one minus the complementary,error function as shown in the slide on the other hand for the edges we,decided to use a combination of two independent model and only among ocean,models the only valuable that's what they know,this present not and if the know this present the pamphlet independently we because value from a gaussian models that that's the weight of the of the,edge so for the experiments what we did was,using classical validation approach to evaluate the precision and recall of,the of our and it follows compared to classical,baseline the similarity based approaches,such as nearest neighbor and nearest prototype OK this is the first set of examples,here we are ten classes of fifteen shapes each so it's two the,shape shape recognition task and what we did was extracting the shock,graphs of these shapes for those of you who don't know what should these simply you given the shape can affect,the skeleton of shape this kind you can think of it as imagine you want to if,what you've all the boundary of the shape in work the largest of the point where the,boundary collapses is this kind of,simple and even the scale which is made by a number of scattered ranges,segment you can construct a graph where,each node corresponds to a kind of the range and this graph node attributes in the,sense that no reflects some the,proportion of the bomb that has created that's kind range so this is the distance metrics of the,costs of the graph and it's multidimensional scaling that,you can't see what probably but and how,i can tell you that there is a lot of class of,overlap between different classes and a lot of stability in the same class so this task is supposed to be quite,hard for me is never miss prototype which are similar to the approach in fact as shown by this graph pursuing,this properties are precision recall our approach actually performs,independently of the training set size,fifteen percent at least fifteen percent better than both nearest,neighbor and nearest prototype OK so this means that we are actually,able to capture these structural evaluation,which is the nearest neighbor and,nearest prototype and as the second set of examples of example,we wanted to test the approach on the shape recognition task this is very similar to the other problem actually this time we compute the three-,dimensional scanner which is also called,a media interface once again we have an attributed graph,well know what we don't know but this time the scale of the task is,quite easy as you can see the distance metrics and his mother,skating show there is absolutely no,overlap between different classes so it's actually in the neighbouring,this prototype to perform both a quite,fine and indeed the case because they almost,always performed independently of the,training set size they obtain a two hundred percent CNN,called what is our model i don't know if you can see it properly,but performs very OK because they produce more than ninety five percent,precision and recall but there is a small gap between the nearest,neighbor is prototype and our approach and these we think is probably due to,the very nice way of estimating the initial correspondences of the metrics,of course if you can diffuse about more you you get better results from the OK wanted to learn also in models the weight on the edges and then we we took a subset of the coil,twenty for each image as you can see i,extracted the most salient corner points,using the corner point detector and unexpected,graph of these with this to this point as you can see probably i didn't use the,parameters so well or maybe the content that wasn't working,so well at home and that was fine with us because we,want to the problem we have so there is much variability the graph not,quite consistent there's a lot of noise,and we like in fact the distance metric the edit,distance metrics and is multidimensional,scaling show it's a complete mess because it's almost impossible to or alternately least is very difficult,to distinguish between example of the,same class the classes you just the nearest neighbour only as prototype,approach on other at least we get that,this plot and that indeed the case as you can see,both the nearest neighbour to nearest prototypes trying to reach in your forty percent precision and recall so while our approach actually reaches,about seventy percent precision and,recall so as you can see in the model is able,to learn despite of the noise of the data which is very noisy is,able to learn generative model can describe the distribution and the,variation of the set quite quite well OK as the last set of examples experiments we wanted to generate some,synthetic data and in order to do so i picked six,generative models i define six generative models and i,assembled fifteen graphs from each of,these models so i did that in order to get a space,where this decide to the valuation was very high i wanted to be a tough problem once,again and this graph if i remember correctly,they are attributed all on nodes so this is the edit cost distance,metrics and is multidimensional scaling and once again we perform very well what's important about the nearest,neighbour in this prototype we achieve almost perfect precision and,recall when training set size goes while both precision and recall and,recall for you neighboring but i cannot go above the eighty percent limit so concluding we have addressed the,problem of graph learning for from,samples we were able to learn the model based on,a for node independence and independent nodes edges independence assumption but a but in this model is to make sure we are,able to some out to extract some correlation between the,nodes we use the passive sampling approach to,overcome the bias of a single estimation,of the correspondences and we use maximum likelihood estimation,to estimate the northern edge parameters and the minimum message length criterion,for pruning the experiment was performed well a wide,range of real world object recognition,task two the shape recognition three d shape,recognition object recognition but according to the set and simply the,data as well and that should be that our approach,outperforms outperforms both,neighbouring prototype quite clearly and an important regardless of the,matching algorithm and distance metric,adopted which was the state of the art so that concludes my talk and if you,have any questions you like all OK o yeah you know o OK i mean the number of iteration that,we need to converge well something in in my master thesis,phases i did not really the network the convergence parameters but at the same,time i just blocked the precision and,recall for defense number of iterations and,correspondences assembled and actually the he might be our approach is able to,estimate the a good model even if we do that no set number of iteration,and correspondences of course the more you assemble and i agree that the,learning process more the good the bad it's easier to your,mother expecially the most important parameter,set is probably the number of correspondences temple because,as i've shown earlier b if you don't estimate if you ask me just,one corresponds to get the bias if you don't estimate enough or in as many and he designed to be that but anyway even if one of the very low,set a number of responses as a twenty to ten per cent or very low,number of iterations you can get a very good precision and,recall so over the o i now o we don't do but it's quite simple because actually,of course it can generate new data as i need for generating synthetic example,datasets for example but for this task in particular that can be quite,difficult because you know i think it is a lot of information from,the from this kind of to the shape you can still keep some,information even if the quantisation,rules introduced the best way to continuum the continued to be the discrete space introduce a lot of,position error but OK i think i think we can still keep,the information when you go to this kind of representation that when,you go from this kind of representation,to the structure graph then sum out in order to represent the,single scattering branch so you should somehow including that i,don't have an or something describing that particular segment or prototype of,that segment so it is possible maybe but it is hard and in nineteen three d shape,recognition more because then you you,each node representatives of face so some kind of you have to model with the way the two
is my work with a with mathias we were,working in the context of aquasmart so this is project that,tries to bring similarly technology on the management,of of aquaculture and what and aquaculture,is basically most of you know a reading fish reading models i will bring cdc life right and it's it's as you know from work and,its it does as yeah this is not new it all six thousand years before christ or it,is being done in in in victorian canada and signed it,doesn't have hundred years before christ then rhode almost which spreading,this and in the eighteenth century there was already some germans,are feeding the fish would produce food so the whole idea off of of,using that and you can imagine that data mining and how how,data mining looks like mecking data back in time right today we are already actually aquaculture today,is is very is becoming more and more important because of the,qualities of both of of the food being coming from the fish we are,expecting a transaction of of nine point seven billion into,thousand fifty and and already the twenty key at twenty,kilo per capita worldwide is reached so so there's more and more does this is million dollar business it's it's not a,joke we are the the companies are more and,more interested on optimising their understandings and production sol,sol tekken technology like case-based,reasoning for for fish disease was used as a visual our,networks for predicting important factor in aquaculture such as,water temperature oxygen levels even a computer vision whether he,had to be able to identify the fish as the for for for for the,growing of our d and so on and more is to be used in in,aquaculture there are even interest on on applying technology of the internet of things and,all the cezar networks the is established to be,able to understand what's going on in the water because,that as i'm going to explain later on is one,of the the most the biggest unknowns and in the,biggest problems in agaric aquaculture today and and this,may be the biggest difference between what's happening today in,agriculture which very much comparable with,aquaculture because because in our culture we know what,going on we can see is going on can tech it's going on in aquaculture,is very different and very difficult but to give you an,idea of how this is growing how is becoming a big b let's say industry we are already consuming more aquaculture products then,then from the real capture many of them being being,question agent with production or something stage with production of,the tree and so on a much also here in the rat address to,coast and in thousand twelve feet was already,almost half how of on on farm raised fish and wild caught,fish and it's expected in thousand thirty to be already to towards on aquaculture based so f our study,targets are does this well known guy if i put this is this kind of,photos because the ones that you may get to meet in a dish i could with much better than the and them let's,better than the scientific drawings and boat the,seed riemann sea bass are very common in the data that exceed and in the atlantic so our our and users are coming from is l greece,spain and ireland so we wanted to have the things that that in the,fisheries would be we could so we could study said,by let's say and to understand the knowns of data in,aquaculture is important to understand what does work flow and,what's happening in aquaculture so fry is as a college,does baby fish are outsource this production is is and by other,companies in the fish the fisheries such as so so so much as as the the fish,the for food or fish food produced is also outsource first so this,is another thing and it's not very much related to the,fisheries the fish is choose what are the other with the ones better,for the production and already when the baby fish the price come to the production and the starting,point we know they add to ten percent of of x fish,that some of them might dined way we don't know how many so already,from the beginning we don't know exactly how many fish are dealing,with it now remember seventy percent of the,costs in aquaculture are fish foods so not knowing how many fish we,have swimming in the water it's very important because we don't to is hard to then to to to optimise,spendings on fish food and for the production itself now another,important step let our use both of them the sampling,and transfer you need to sample the fish to understand as heads,several levels what's going on in terms of of average weight of the,fish and so on and to be able also to,transfer the fish that are growing faster than other to other,classes and these processes are complicated,because because when you take the fish out of,water it will become age will have tom effect on the fish which means that the fish would probably not grow,for one week which is really really a lot of time in,the fish production in the one that so you are you are unable to,actually take all the fish out and put them back,again you can you know that many of them will die and there,will be a really really big shock on production so it only really,really know the number of fish and get the our first time when,take amount when classify them when you put it as so we are dealing here i'm going to best,is dealing here with which several kinds that of course,continues and screed like average weight in a number of fish also,also it is important for us to to to process what are the species and and and have some estimations on on,on the quality of the fish of the fish for example from,starting at some point now it is also important to distinguish the data that changes over time the data,that are doesn't change over time and when it changes over time what is the data that is daily and what,is not furthermore i mean we have the fication,data that is very relevant to the we'd and i should have so and in that i,should i wrote that there are two things that you,consider that's the unit in the bet so when i talk about bands i mean,like like the place where a group of fish is and,the unit is like the issue units so so that's how we we don't,fightings and when when the fish is to growth for,the for the standard growing of the fish in one batch just put it to,the other bet so that you know what kind of language using now,daily data is relevant because we're trying to,measure these they by day but we really can only check our our,models and how are they close to reality when we across that which,sampling data life time data left date data is also,relevant because it's an shows when historical of data on that,growing process of one bad now in that the accuracy of the data is also,affected in tree different classes so you have direct values that that come from the sampling order come,directly from the measuring of average temperature and option level but you also have the calculated values based on direct others and in based on,on models and and there have values are coming from calculated fcr table i'm going to explain that in in more detail so we we lose our system was designed so,that the fish farmer when it provides it's it provides data,in the first the first thing we'll be dealing with syntactic,cleaning which means we have problems on the or even rds this,as the files coming to our hands on on on the missing data,that needs to be somehow completed the the the i was that are not,coming i'm coming well so we have you can imagine that most of,the data is put them by hands and and the the accuracy of for the fish,farmers in putting data a is of course a non not,not like the machine accuracy would be plus for example you have you,have situations where you want to count the that fish so it was,also that you cannot cannot know because you have you have swimmers,have and what he so diverse that that will go,and try to count the fish but they also ignore the s small,number of fish are counted there's a lot of on here a plus you have,semantic cleaning which means which are regards also very much,of of values that are net a incorrect in in,in that are not matching some and all these needs to be d needs,to be the is a instamatic cleaning here i'm i'm,just talking about or he values that are there i clean that,are not consistent with a with holes uses,all kinds yeah by yeah yeah yeah and and and in yeah as a well s somebodies ladies and,only get he he knows what kind of a a a i have to have a really ok and we are it's tell you about the feed,conversion radio which ratio which is one of the most relevant,indexes in aquaculture we are telling you about how much the food are much the food that,you're giving to the fish really impacted on the growing of the,fish say so we are dealing with to different,kinds of fcr economical fcr in biological fcr where in one case,you just care about that the net grote so rule how much,exactly the the fish grow without without counting,or any other x factors and ends with a logical fcr you are also,interested on on biomass mortalities and biomass of,adjustments and so on other other measure that is important,for for the fish farmers is a specific feed rate which which is,percentage regarding daily feed and biomass now the models used by fish farmers our using our let's say looking at the fcr,so the feed conversion rate you based on only to variables the water,temperature and and average weight now dc model that,we developed this is based on historical data but there are a lot,of hidden variables here for instance when we so that's the fish,it's more or they need to eat more to roll at regular level when,the waters to called we know that when the fish is all enough for the reproduction is actually doesn't,really matter how much feed because that's why is that the,declination and because they actually covered are called,of water with sexual reproduction reproduction and when the water is to warm the off-,season levels on water really drop down so so there's a big big,increase of of the needs of of the flow of the,food for the fish to keep a standard row quote that all yeah yeah,yeah use that they they don't know these and,and a and the problem here is that the the,missing or so the missing of data usually is a is,compensated with with the with the standard experience of,the fish farmer that knows all these things if we want our automatised that we need,we need we are using the the machine learning to be able to,based on historical data try to get that experience of the fish,farmer out in in models and here i can see i can show,you how it looks with real data and and with the,model and he all speaks are based on the,adjustment on the same samples that time based on time dcr for all for,the same fish for for different fisheries and and also the fact that a every given force is to,some other other other factors also changes a little bit of that said the behavior of that but but,that the that is the the the date the,behavior of the curve or the same in in detail the same sorry and the,the case of and we have we have built for public interface for,aquasmart project for the for the user for the fish farmer to input their own data and and self are,used to models to be able to simulate simulates production case of success is one of our end users which had the want them to send modeled use with with technology they had back,home and you can see that the the model is in,the red line and the blue line is a real data that,was captured at each each is simple and and with our,with our new model they were able to be globe much closer,to the to the much closer to the to the problem,to the reproduction and and have much better expectations on,on that production failed s sorry the model is read and the,real data is blue you in both of them our model is here in,direct so that's the model that they were using before he because,here as yes yes yes yes yes yes talking about several council knowledge cannot really,read the numbers what are the differences bigger and specially,on on the towards the end you see that is already is already the,difference is already doing quite a lot in in in the in the,time so this is actually the counting average weight,over time ok so this is very important for the,production itself know rival to follow and any other,details about this project in about how these techniques are,implemented in in in aquaculture our just direct me to any any of your interest on how to implement,or ideas and it have to which of course for a we are we have the model the model is,not available publicly but we have it's we have to called a,kind with which form it's it's it's it's completed yeah using k is nearestneighbours for the,covering of the machine data we don't have and why didn't go to the wars is a,modelling because just this was yeah the data knowledge this is a joke of on
